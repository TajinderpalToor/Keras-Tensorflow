{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3ctCONjkEhnQWdXz1a72O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"EYl6_QXLk6G7","executionInfo":{"status":"ok","timestamp":1698105003898,"user_tz":240,"elapsed":127,"user":{"displayName":"tj toor","userId":"12772828922137278049"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","from tensorflow.keras.datasets import mnist\n","\n","import pandas as pd"]},{"cell_type":"markdown","source":["Looking at Functional API and when to use it -- we are looking at the MNIST dataset with two digits per picture\n","\n","cant use sequential becasue it maps one input to one output and we are having two outputs"],"metadata":{"id":"h0bdzVPcxaPz"}},{"cell_type":"code","source":["# HYPERPARAMETERS\n","BATCH_SIZE = 64\n","WEIGHT_DECAY = 0.001\n","LEARNING_RATE = 0.001\n","\n","import os\n","\n","train_df = pd.read_csv(\"/train.csv\")\n","test_df = pd.read_csv(\"/test.csv\")\n","train_images = os.getcwd() + \"/train_images/\" + train_df.iloc[:, 0].values\n","test_images = os.getcwd() + \"/test_images/\" + test_df.iloc[:, 0].values\n","\n","train_labels = train_df.iloc[:, 1:].values\n","test_labels = test_df.iloc[:, 1:].values\n","\n","\n","def read_image(image_path, label):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n","\n","    # In older versions you need to set shape in order to avoid error\n","    # on newer (2.3.0+) the following 3 lines can safely be removed\n","    image.set_shape((64, 64, 1))\n","    label[0].set_shape([])\n","    label[1].set_shape([])\n","\n","    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n","    return image, labels\n","\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","train_dataset = (\n","    train_dataset.shuffle(buffer_size=len(train_labels))\n","    .map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","test_dataset = (\n","    test_dataset.map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")\n"],"metadata":{"id":"k7YTYkVYlkt2","executionInfo":{"status":"ok","timestamp":1698105007679,"user_tz":240,"elapsed":355,"user":{"displayName":"tj toor","userId":"12772828922137278049"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["print(train_dataset)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJBvYaun7jDQ","executionInfo":{"status":"ok","timestamp":1698105008913,"user_tz":240,"elapsed":169,"user":{"displayName":"tj toor","userId":"12772828922137278049"}},"outputId":"c6a4e1d4-c688-4000-d4e5-7c528be1a8eb"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name=None), {'first_num': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'second_num': TensorSpec(shape=(None,), dtype=tf.int64, name=None)})>\n"]}]},{"cell_type":"code","source":["from keras.src.backend import batch_normalization\n","# Build Model\n","\n","inputs=keras.Input(shape=(64,64,1))\n","x=layers.Conv2D(filters=32,kernel_size=3,padding='same',kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(inputs)\n","x=layers.BatchNormalization()(x)\n","x=tf.keras.activations.relu(x)\n","\n","x=layers.Conv2D(64,3,kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(x)\n","x=layers.BatchNormalization()(x)\n","x=tf.keras.activations.relu(x)\n","x=layers.MaxPooling2D()(x)\n","\n","x=layers.Conv2D(64,3,activation='relu',kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(x)\n","x=layers.Conv2D(128,3,activation='relu')(x)\n","\n","x=layers.MaxPooling2D()(x)\n","x=layers.Flatten()(x)\n","x=layers.Dense(128,activation='relu')(x)\n","x=layers.Dropout(0.5)(x)\n","x=layers.Dense(64,activation='relu')(x)\n","\n","output1=layers.Dense(10,activation='softmax',name='first_num')(x)\n","output2=layers.Dense(10,activation='softmax',name='second_num')(x)\n","\n","\n","# you have two outputs so can make it a list\n","\n","model= keras.Model(inputs=inputs,outputs=[output1,output2])\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n","    loss=[\n","    keras.losses.SparseCategoricalCrossentropy(),\n","    keras.losses.SparseCategoricalCrossentropy()\n","    ]\n",")\n","\n","model.fit(train_dataset,epochs=5,verbose=2)\n","model.evaluate(test_dataset,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"ilZF5OA3zOwa","executionInfo":{"status":"error","timestamp":1698105013565,"user_tz":240,"elapsed":2922,"user":{"displayName":"tj toor","userId":"12772828922137278049"}},"outputId":"e255655a-7d1f-4bf4-9a13-52f5abd6f1d6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-a692b7dbce31>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n/content/train_images/84_97.png; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_10117]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"B-wPQMBO2EM8"},"execution_count":null,"outputs":[]}]}